---
title: "Laboratorio 1"
output:
  html_document:
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Librerie necessarie all'analisi:

```{r}
require(maptools)
require(rgdal)
```

I cinque file dbf, sbn, sbx, shp, shx servono a produrre la mappa su R, ma soltanto dbf shp e shx sono essenziali. 

```{r}
lomb.poly <- readOGR("lombardia.shp", verbose=T)
plot(lomb.poly)
```

Lettura dati:

```{r}
inc = incendi <- read.table("Incendi_2003.csv", header=T,sep=";")
str(incendi)
```

Le coordinate sono espresse in Gauss-Boaga.

Abbiamo 380 osservazioni

```{r}
plot(lomb.poly)
points(incendi$EstN,incendi$Nord)
```

## Dati areali

```{r}
aus.poly <- readShapePoly("austrianuts3.shp", IDvar="ID",verbose=TRUE)
plot(aus.poly,col = "green",border="red")
```

35 province austria codificate con 35 poligoni: shape di tipo poligonali

```{r}
slotNames(aus.poly)
```

Questi slot contengono tutta l'informazione contenuta in tutto lo shape file. 

* data: Per accedere a data si può usare equivalentemente `slot(aus.poly, "data")` e `aus.poly@data`. 

*  polygons:

```{r}
a = slot(aus.poly, "polygons")
length(a)
```

Ognuno dei 35 elementi contiene tanta informazione. L'elemento più importante è coords ovvero coordinate lat e long di 335 punti, ovvero i punti che sono identificati sul bordo del confine di quel poligono che servono a rappresentare appunto il poligono. La geocodifica avviene tramite coordinate angolari.

```{r}
centr=coordinates(aus.poly)
```

`centr` (ossia centroide) è una matrice di 35 righe e 2 colonne (lat e long). Ogni riga è un'area, una provincia diversa.
 
```{r}
plot(aus.poly,col = "green",border="red")
points(incendi$EstN,incendi$Nord)
points(centr,col="red")
text(centr[,1],centr[,2],aus.poly$ID,col="blue")
```


Per estrarre un pezzo dello shape:

```{r}
xx<-aus.poly[aus.poly$ID=="AT13",] # Vienna
plot(xx)
```


## Processi di punto
```{r}
require(spatstat)
ppp<-incendi[,c("EstN","Nord")]
ppp0=as.ppp(ppp,W=lomb.poly);ppp0 ##informazione combinata
plot(ppp0,cex=0.5,main=,"Incendi in Lombardia nel 2003")
```

Processi con marcature (mark = estensione incendio)

```{r}
ppp<-incendi[,c("EstN","Nord","Ettari")] # disposizione fissa
ppp0=as.ppp(ppp,W=lomb.poly,mark=ppp$Ettari);ppp0
plot(ppp0,main=,"Incendi in Lombardia nel 2003 differenziati per estensione")
```

## TEST CSR

```{r}
d<-read.table("WLR300.txt",header=T) 
str(d)				
```

Test per vedere se è CSR.

W = finestra; Supporto = cerchio di raggio 960550 micron, circa 10 cm di raggio; disc = funzione di questa libreria che permette di costruire palle d-dimensionali.

```{r}
 W <- disc(96950, c(0,0))	# finestra circolare in 0,0 = centro del wafer
pp<-ppp(d$X,d$Y,window=W); summary(pp)
```

Sommario: 66 punti; 

average intensity = #Eventi / Area Supporto = stima del parametro lambda **SE il processo fosse omogeneo**

Single connected closed polygon = approssima il cerchio con una superficie di 128 vertici 

```{r}
plot(pp,cex=0.6,main="locazioni eventi",cex.main =1.2,lwd=3)
```

### Test basato sul quadrat counts 

```{r}
qx<-quadratcount(pp,4,4)	### tabella 4x4
plot(qx)
```

Con quadratcounts partiziono le aree del cerchio in cellettine e conto quanti eventi trovo in quell'area. 

quadratcounts(oggettoppp, #celleascisse, #celle ordinata)

Per produrre il test basato sul chi quadro: 

```{r}
te0<-quadrat.test(pp,4); te0
```

DF = 16 celle - 1 = 15

Test BILATERALE di RIFIUTO: pvalue molto piccolo --> HP di CSR non sembra valida

```{r}
plot(te0, col="red", cex=1, lty=1.5, lwd=3,bg = gray(0.7))
```

Informazione osservata = in alto a sx.

Informazione attesa = in alto a dx

Valore in basso = residuo di Pearson = (exp-obs)/exp

```{r}
plot(te0, col="red", cex=1, lty=1.5, lwd=3,bg = gray(0.7))
plot(pp, pch="+", cols="green", cex=1.5, lwd=1.2,add=T)
```

Rifare con 10x10 celle:
```{r}
qx10<-quadratcount(pp,10,10)	### tabella 10x10
plot(qx10)
te10 <- quadrat.test(pp,10)	###test dispersione per 10x10
te10
```

Respingo ancora hp nulla. Il numero di eventi è troppo basso rispetto al numero di celle implementate --> Warning.

### Test non quadrat counts

Valutare presenza di clustering.

Distanza dal primo vicino:

```{r}
hist(nndist(pp),main="distanza dal primo vicino",xlab="distanza")
```

Coda sinistra molto alta --> ci aspettiamo ci sia cluster

**Test basato sulla distribuzione del NN**:

Creiamo un oggetto GGb che poi plotteremo. il test si basa sulla distribuzione empirica vs teorica

```{r}
GGb<-Gest(pp, r=NULL, breaks=NULL,correction="none")
plot(GGb, raw ~ r,main="FR della distanza dal primo vicino",xlab="r")
plot(GGb, theo~ r,add=T,col=2,lty=3)
legend(25000, 0.2,  legend=c("F.R. empirica","F.R. teorica"),lty=c(1,3), col=c(1,2),bty="n")
```

**Inviluppo** Montecarlo per test CSR

Simulo 100 volte MC, calcolo min e max in ogni punto per creare la griglia

```{r}
envpp<-envelope(pp,fun=Gest,nsim=100,nrank=,verbose=TRUE,saveall=F)
a = plot(envpp,main="inviluppo MC",xlab="y")
a
```


## Stima kernel intensità 

```{r}
Z <- density.ppp(pp, 15000)
plot(Z,main="mappa dell'intensità kernel"); 
plot(pp,add=T,cex=0.6,col="black")
persp(Z) 
```

Sulla Lombardia:

```{r}
lomb.poly<-readShapePoly("lombardia.shp",verbose=TRUE)
ppp=incendi[,c("EstN","Nord")]
ppp0=as.ppp(ppp,W=lomb.poly);ppp0
plot(ppp0,cex=0.5,main=,"Incendi in Lombardia nel 2003")
```

Stima dell'intensità:

```{r}
Z <- density.ppp(ppp0, varcov=diag( c(var(ppp$EstN),var(ppp$Nord))/16)) 
plot(Z,main="mappa dell'intensità kernel"); 
plot(ppp0,add=T,cex=0.4)
```

Rispetto a prima ho cambiato il parametro di lisciamento:

```{r}
varcov=diag( c(var(ppp$EstN),var(ppp$Nord))/16); varcov
```

Sto passando una matrice di varianze covarianze , con parametri di lisciamento proporzionali alla variabilità della componente. Compenso la variabilità nelle direzioni varie con un parametro di lisciamento pià elevato. 

Il /16 serve per aggiustare empiricamente la mappa;

Per scegliere h si potrebbero avere delle funzioni che cross validando trovano l'h, il problema è che tendono ad essere "troppo locali".